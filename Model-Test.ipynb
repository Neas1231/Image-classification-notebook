{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6afa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import neptune\n",
    "#import splitfolders # Библиотека для разделения файлов картинок на train test\n",
    "import matplotlib.gridspec as gridspec\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c74f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'C:\\data\\dataset'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f874438",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92816e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 60.,  12.,   3.,   2.,   1.,   1.,   5.,   0.,  15.,   0.],\n",
      "        [  9.,  83.,   4.,   8.,   0.,   0.,  12.,   0.,  12.,   1.],\n",
      "        [  4.,   8., 113.,   4.,   0.,   0.,   6.,   0.,  12.,   0.],\n",
      "        [  0.,   1.,   2., 129.,   3.,   0.,   5.,   0.,  25.,   0.],\n",
      "        [  0.,   2.,   0.,   5.,  43.,   0.,   8.,   0.,   6.,   0.],\n",
      "        [  0.,   0.,   1.,   4.,   0.,  35.,   3.,   0.,   0.,   0.],\n",
      "        [  4.,  13.,   5.,   4.,   0.,   1., 129.,   0.,  21.,   0.],\n",
      "        [  0.,   4.,   0.,   0.,   0.,   0.,   0.,  20.,   2.,   2.],\n",
      "        [  4.,   5.,   3.,  16.,   0.,   0.,  21.,   0., 113.,   0.],\n",
      "        [  1.,   1.,   0.,   2.,   0.,   0.,   6.,   0.,   0.,  59.]])\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet50()\n",
    "\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    "model_ft.load_state_dict(torch.load('weights-0.894737acc-0.2899loss.pth',map_location ='cpu'))\n",
    "\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7615531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6061, 0.6434, 0.7687, 0.7818, 0.6719, 0.8140, 0.7288, 0.7143, 0.6975,\n",
      "        0.8551])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix.diag()/confusion_matrix.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d37f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68   9   2   0   0   0   6   0  14   0]\n",
      " [  7  88   5   5   0   0  15   0   9   0]\n",
      " [  6   6 112   5   0   1   7   0  10   0]\n",
      " [  3   1   2 128   4   0   7   0  20   0]\n",
      " [  0   0   0   6  43   0   6   0   9   0]\n",
      " [  0   0   3   2   0  31   7   0   0   0]\n",
      " [  2   9   4   3   1   0 134   0  24   0]\n",
      " [  2   2   0   0   1   0   1  21   0   1]\n",
      " [  4   4   1  13   1   0  19   0 120   0]\n",
      " [  2   3   1   0   0   0   4   0   1  58]]\n",
      "[68.68686869 68.21705426 76.19047619 77.57575758 67.1875     72.09302326\n",
      " 75.70621469 75.         74.07407407 84.05797101]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "print(conf_mat)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print(class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b27610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
