{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6afa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import neptune\n",
    "import matplotlib.gridspec as gridspec\n",
    "cudnn.benchmark = True\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c74f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'E:\\datasets\\dataset'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f874438",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92816e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = models.resnet50()\n",
    "\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    "model_ft.load_state_dict(torch.load('weights-resnet.pth',map_location ='cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d37f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74        99\n",
      "           1       0.70      0.66      0.68       129\n",
      "           2       0.91      0.84      0.87       147\n",
      "           3       0.72      0.81      0.77       165\n",
      "           4       1.00      0.69      0.81        64\n",
      "           5       1.00      0.81      0.90        43\n",
      "           6       0.76      0.76      0.76       177\n",
      "           7       1.00      0.79      0.88        28\n",
      "           8       0.66      0.80      0.72       162\n",
      "           9       0.98      0.87      0.92        69\n",
      "\n",
      "    accuracy                           0.78      1083\n",
      "   macro avg       0.85      0.78      0.81      1083\n",
      "weighted avg       0.79      0.78      0.78      1083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device=device)\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        from sklearn.metrics import classification_report\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "\n",
    "print(classification_report(lbllist.numpy(), predlist.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6595318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "with torch.no_grad():\n",
    "     for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "print(classification_report(lbllist.numpy(), predlist.numpy(), target_names=class_names, digits=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
